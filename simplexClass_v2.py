import numpy as np
import C0HomDeg1_simplicialComplex_embedder_2_for_array_of_reals_as_multiset as simplex2
from distinct_permutations import distinct_permutations
from itertools import chain, combinations, product, permutations
from tools import sort_np_array_rows_lexicographically
from math import factorial

#returns powerset without the initial empty tupel
def powerset(s: list):
    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1))

#Function used to generate vertices according to the rule that pre-existing ones in the eji_lincomb must be preserved
#This is essentially barycentric subdivision:
#For a simplex with vertices in a double nested seed list e.g. of form [[[1,0 ,0]], [[0,1,0]], [[0,0,1]]]
#After all recursions will then return the simplices on the barycentric subdivision that can be generated from this
#(the actual barycentre e.g. [1,1,1] is omitted as it is the same for all simplices
#In this example return will be: [ [[1,0,0],[1,1,0]], [[1,0,0],[1,0,1]], [[0,1,0],[1,1,0]], [[0,1,0],[0,1,1]], [[0,0,1],[1,0,1]], [[0,0,1], [0,1,1]] ]
def recursive_step(l: list):
    new_l = l.copy()
    original_l = len(new_l)
    for i in range(original_l):
        if new_l[i][-1].count(0) == 1:
            return new_l
        else:
            for j in range(len(new_l[i][-1])):
                if(new_l[i][-1][j] == 0):
                    copy = new_l[i][-1].copy()
                    copy[j] += 1
                    edit = new_l[i].copy()
                    edit.append(copy)
                    new_l.append(edit)
    for i in range(original_l):
        new_l.pop(0)
    return recursive_step(new_l)

#essentially same class as eji_LinComb with some added functionality (mainly summing with other vertices and a function to translate an array to a vertex with that array as eji_counts
class Vertex(simplex2.Eji_LinComb):

    #Note that adding does not commute with other class operations, in particular not with value or to_array
    #e.g. a.value(dim)+b.value(dim) != (a+b).value(dim)
    def __add__(self, other):
        ans = Vertex.__new__(Vertex)
        ans._index = self._index+other._index
        ans._eji_counts = self._eji_counts+other._eji_counts
        return ans

    def value(self, dim):
        return self.get_canonical_form().hash_to_point_in_unit_hypercube(dim)

    def to_array(self):
        return self.get_canonical_form()._eji_counts

    def get_canonical_form(self):
        ans = Vertex.__new__(Vertex)
        ans._index = self._index
        ans._eji_counts = sort_np_array_rows_lexicographically(self._eji_counts)
        return ans

    def array_to_vertex(ejis: np.array):
        ans = Vertex.__new__(Vertex)
        ans._index = 1
        ans._eji_counts = ejis
        return ans

#Class to hold groups (lists) of vertices and compare them + geometric functionality
class Simplex():
    
    def __init__(self, n: int, k: int, vlist: list[Vertex]):
        self.n = n
        self.k = k
        self.dim = 2*(n-1)*k+1
        self.vlist = vlist
        self.num = len(vlist)

    #compares canonicalisations of simplices - technically no longer needed as only used in SimplexMap.remove_equivalent_simplices()
    def __eq__(self, other):
        if (self.n != other.n) or (self.k!=other.k) or (self.num!=other.num): return False
        array_list_self = []
        array_list_other = []
        for i in range(self.num):
            array_list_self.append(self.vlist[i].to_array())
            array_list_other.append(other.vlist[i].to_array())
        a = sorted(array_list_self, key = lambda x: tuple(x.flatten()))
        b = sorted(array_list_other, key = lambda x: tuple(x.flatten()))
        return all(np.array_equal(x, y) for x,y in zip(a, b))

    #combines list of two simplices -> used when an (n-1)-dimensional simplex for a single value of k is combined with the others to form an (n-1)*k-dimensional simplex
    def __add__(self, other):
        assert(self.n == other.n and self.k == other.k)
        temp = self.vlist.copy()
        return Simplex(self.n , self.k, self.vlist+other.vlist)

    #returns Simplex generated by canonicalised vertices
    def get_canonical_form(self):
        new_vertices = [vertex.get_canonical_form() for vertex in self.vlist]
        return Simplex(self.n, self.k, new_vertices)
                
    #uses recursive_step function (see beginning of code)
    def barycentric_subdivision(self):
        barycentre = sum(self.vlist, start=Vertex(self.n, self.k))
        simplex_list =[]
        seed_list = []
        a = np.zeros(self.num)
        a[0] += 1
        for perm in distinct_permutations(a):
            seed_list.insert(0, [list(perm)])
        allowed_vertex_combos = recursive_step(seed_list)
        for combo in allowed_vertex_combos:
            temp_vlist = [barycentre]
            for ele in combo:
                new_vertex = sum([self.vlist[i] for i in filter(lambda i: ele[i], range(self.num))], start = Vertex(self.n,self.k))
                temp_vlist.append(new_vertex)
            simplex_list.append(Simplex(self.n, self.k, temp_vlist))
        return simplex_list
    

    #calculates projection of a point in the 2(n-1)k+1 dimensional space onto a given subspaces/simplex with vertices v_i by using the condition that at for point p point and projected point p_0 = lamda_i*v_i, (p-p_0) dot v_i = 0 <-> p dot v_i = lamda_j*(v_j dot v_i)
    def projected_point(self, p: np.ndarray):
        assert len(p) == self.dim
        n = self.num
        b = np.zeros(n)
        A = np.zeros(shape=(n,n))
        for i in range(n):
            b[i] = np.dot(p, self.vlist[i].value(self.dim))
            for j in range(n):
                A[i,j] = np.dot(self.vlist[i].value(self.dim), self.vlist[j].value(self.dim))
        assert np.linalg.det(A) != 0
        lamda  = np.linalg.solve(A, b)
        projection = np.zeros(self.dim)
        for i in range(n):
            projection += lamda[i]*self.vlist[i].value(self.dim)
        return projection, lamda, self.vlist

    def distance_to_point(self, p: np.ndarray):
        projection = self.projected_point(p)[0]
        return np.linalg.norm(p-projection, ord=2)

#Code in red comments in the following class is the original code with exploding runtime, actual code runs fast but has not yet been thoroughly checked
class Simplex_Map():

    #There is no known use for setting subdivided=False, but kept as a toggle just in case
    def __init__(self, n, k, subdivided = True):
        self.n = n
        self.k = k
        
        temp_list = self.simplices_across_all_k(self.n, self.k)
        
        print("Post_cutoff length: ", len(temp_list))
        if subdivided:
            simplex_list = []
            for simplex in temp_list:
                simplex_list += simplex.barycentric_subdivision()
        else:
            simplex_list = temp_list
        
        print("Post_subdivision length: ", len(simplex_list))

        self.slist = simplex_list

        """
        self.slist = self.remove_equivalent_simplices(n, k, simplex_list)
        
        #print("Post_reduction length: ", len(self.slist))
        """

        

    #generates a vertex from an eji_list in 1 k-dimension
    def list_to_vertex(self, lt: list, n, k, kmax):
        assert len(lt) == n
        vertex = Vertex(n,kmax,[])
        for l in range (n):
            if(lt[l] != 0):
                vertex.add(simplex2.Maximal_Simplex_Vertex({simplex2.Eji(j=l,i=k)}))
                #index is hard coded to 1 here so that the index of final vertices in the full dimension matches the ones generated in the encoder -> otherwise hash function will generate different vectors in hypercube
                vertex._index = 1
        return vertex

    #generates simplices inside 1 k-dimension
    def generate_simplices_for_single_k(self, n, k, kmax):
        seed_list = []
        a = np.zeros(n)
        a[0] += 1
        for perm in distinct_permutations(a):
            seed_list.insert(0, [list(perm)])
        temp_list = recursive_step(seed_list)
        simplex_list = []
        for ele in temp_list:
            vlist = []
            for v in ele:
                vlist.append(self.list_to_vertex(v, n, k, kmax))
            simplex_list.append(Simplex(n, kmax, vlist))
        return simplex_list

    #It should be possible to introduce the cutoff earlier in this function, if not in the first then certainly in the second for-loop
    #However generating the non-subdivided simplices is entirely negligible compared to other operations, and the small amount of runtime that could be saved is probably not worth the risk of other bugs arising from interactions with the unpacking or the product() method
    #POST: returns the list of all unique (i.e. non equivalent after canonicalisation) simplices before subdivision
    def simplices_across_all_k(self, n, k):
        superlist = []
        simplex_list = []
        cutoff = factorial(n)**(k-1)
        
        for i in range(k):
            superlist.append(self.generate_simplices_for_single_k(n, i, k))
        for simplex_comb in product(*superlist):
            simplex_list.append(sum(simplex_comb, start=Simplex(n,k, [])))
        
        return simplex_list[:cutoff]

        #iterates through all simplices, calcs distance to point and returns simplex that is closest to point  
    def choose_simplex(self, p: np.ndarray):
        dist_list = []
        simplex_list = self.slist
        print("Default: ", simplex_list[0].vlist)
        dist_list = [x.distance_to_point(p) for x in simplex_list]
        print(min(dist_list))
        chosen_simplex = simplex_list[min(enumerate(dist_list), key = lambda x: x[1])[0]]
        print("Chosen simplex: ", chosen_simplex.vlist)
        return chosen_simplex

        #returns the lamda_i and vertices (that were hashed to the hypercube) of the projected_point (within error of the actual point)
    def get_lin_comb(self, p: np.ndarray):
        simplex = self.choose_simplex(p)
        lin_comb = simplex.projected_point(p)[1]
        print("Projection is: ", simplex.projected_point(p)[0])
        return lin_comb, simplex.vlist  

    #previous limiting factor on the runtime was during this function applied to list of barycentric subdivisions - no longer needed 
"""
    def remove_equivalent_simplices(self, n ,k, simplex_list):
        reduced_list = []
        index_list=[]
        
        for simplex in simplex_list:
            if simplex not in reduced_list:
                reduced_list.append(simplex.get_canonical_form())
        for i in range(len(simplex_list)):
            simplex = simplex_list[i]
            if simplex not in reduced_list:
                reduced_list.append(simplex.get_canonical_form())
                index_list.append(i)
        #with open("unique_indices.txt", "w") as file:
            #for index in index_list:
                #file.write(f"{index}\n")
        return reduced_list
"""   
        

class Decoder():                


    def decode(self, n ,k , data):
        ans = np.zeros(shape = (n,k))
        for i in range(n):
            ans[i] += data[:k]
        print(ans)
        data = data[k:]
        
        deltas, ejis = Simplex_Map(n,k).get_lin_comb(data)
        ejis = [eji.to_array() for eji in ejis]
        raw_lin_comb = zip(deltas, ejis)
        lin_comb = self.fix_lin_comb(raw_lin_comb)
        for i in range(len(lin_comb)):
            ans += lin_comb[i][0]*lin_comb[i][1]      
        return ans

#takes linear combination, sorts and permutes the vertices to the way they were originally generated, also normalizes deltas
    def fix_lin_comb(self, unfixed_lin_comb):
        lin_comb = sorted(unfixed_lin_comb, key = lambda x: sum(x[1].flatten()))
        for i in range(len(lin_comb)):
            lin_comb[i] = list(lin_comb[i])
        n = len(lin_comb[0][1])
        k = len(lin_comb[0][1][0])
        for i in range(1, (n-1)*k):
            benchmark = lin_comb[i-1][1]
            fixed_array = np.zeros(shape=(n, k))
            perms = list(permutations(lin_comb[i][1]))
            arrays = [np.stack(p) for p in perms]
            for array in arrays:
                diff = array-benchmark
                cond1 = (np.max(diff)==1)
                cond2 = all(diff.flatten() >= 0)
                cond3 = (np.sum(diff.flatten())<=(n-1))
                if cond1 and cond2 and cond3:
                    fixed_array = array
                    break
            lin_comb[i][1] = fixed_array
            lin_comb[i][0] /= (i+1)
        
        return lin_comb
            
        


if __name__ == "__main__":
    some_input = np.asarray([[2, 4, 3], [1, 6, 2], [8,3,5]])
    n = len(some_input)
    k = len(some_input[0])
    embedder = simplex2.Embedder()
    output = embedder.embed(some_input, debug = True)

    print("Embedding:")
    print(f"{some_input}")
    print("leads to:")
    print(f"{output}")

    print("Decoding then gives:")

    decoder = Decoder()
    decoded_input = decoder.decode(n, k, output[0])
    print(f"Decoded: {decoded_input}")

    
    
        
        
    
        
        
        
            
                

        
    